{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import mediapipe as mp\n",
    "import datetime\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Reshape, LSTM, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "#%matplotlib inline \n",
    "import copy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import models\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot Keypoints using MediaPipe Holistic AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawText(img,sText,x,y):\n",
    "    font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    posf = (x,y)\n",
    "    fontScale              = 5\n",
    "    fontColor              = (255,255,255)\n",
    "    thickness              = 1\n",
    "    lineType               = 2\n",
    "    print(\"Masuk\")\n",
    "    cv2.putText(img,sText, \n",
    "        posf, \n",
    "        font, \n",
    "        fontScale,\n",
    "        fontColor,\n",
    "        thickness,\n",
    "        lineType)\n",
    "    return copy.deepcopy(img)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. Initialize New File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFileName():\n",
    "        x = datetime.datetime.now()\n",
    "        s = x.strftime('%Y-%m-%d-%H%M%S%f')\n",
    "        return s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Create a New Directory to store File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDir(path):\n",
    "    ls = [];\n",
    "    head_tail = os.path.split(path)\n",
    "    ls.append(path)\n",
    "    while len(head_tail[1])>0:\n",
    "        head_tail = os.path.split(path)\n",
    "        path = head_tail[0]\n",
    "        ls.append(path)\n",
    "        head_tail = os.path.split(path)   \n",
    "    for i in range(len(ls)-2,-1,-1):\n",
    "        sf =ls[i]\n",
    "        isExist = os.path.exists(sf)\n",
    "        if not isExist:\n",
    "            os.makedirs(sf)\n",
    "NamaDataSet = \"Kata\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Draw Landmarks / Create Skeletal Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(bimage, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "   # mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                            # mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                            # mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                            # ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Dataset from LIVE Camera Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataset(NoKamera,NamaDataSet):\n",
    "    DirektoriData = \"A:\\\\buat anaconda\\\\dataimage\"+\"\\\\\"+NamaDataSet\n",
    "    #+\"\\\\\"+GetFileName()    \n",
    "    CreateDir(DirektoriData)        \n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_holistic = mp.solutions.holistic\n",
    "    imsize=(640, 480)\n",
    "    TimeStart = time.time() \n",
    "    TimeNow = time.time() +10\n",
    "    FrameRate = 10\n",
    "    \n",
    "    \n",
    "    cap = cv2.VideoCapture(NoKamera,cv2.CAP_DSHOW)\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "      \n",
    "      while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "          print(\"Ignoring empty camera frame.\")\n",
    "          # If loading a video, use 'break' instead of 'continue'.\n",
    "          continue\n",
    "    \n",
    "\n",
    "        image.flags.writeable = False                  # Image is no longer writeable\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, imsize)\n",
    "        results = holistic.process(image)                 # Make prediction\n",
    "        \n",
    "        image_height, image_width, _ = image.shape\n",
    "        \n",
    "        coords = []\n",
    "        coordsy = []\n",
    "      \n",
    "        if not results.pose_landmarks:\n",
    "            continue\n",
    "            \n",
    "        for A in results.pose_landmarks.landmark:\n",
    "            \n",
    "            if (A.x>0.01)and(A.x<1-0.01)and(A.y>0.01)and(A.y<1-0.01):\n",
    "                cx, cy = A.x * image_width, A.y*image_height \n",
    "                coords.append(cx) \n",
    "                coordsy.append(cy)\n",
    "        if len(coords) ==0:\n",
    "            continue\n",
    "        elif len(coordsy) ==0:\n",
    "            continue\n",
    "\n",
    "        #if results.pose_landmarks:\n",
    "        #    pose_landmarks = results.pose_landmarks.landmark\n",
    "        #    for A in pose_landmarks:\n",
    "        #      cx, cy = A.x * image_width, A.y*image_height                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "        #      coords.append(cx) \n",
    "        #      coordsy.append(cy) \n",
    "\n",
    "        x_max = max(coords)\n",
    "        y_max = max(coordsy)\n",
    "        x_min = min(coords)\n",
    "        y_min = min(coordsy)\n",
    "            \n",
    "\n",
    "        cv2.rectangle(image, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (255, 255, 0), 2)\n",
    "\n",
    "        if (int (x_max) < 0):\n",
    "            x_max = 1\n",
    "        elif (int (x_min) < 0):\n",
    "            x_min = 1\n",
    "        elif (int (x_max) < 0):\n",
    "            y_max = 1\n",
    "        elif (int (x_min) < 0):\n",
    "            y_min = 1   \n",
    "            \n",
    "        image.flags.writeable = True                   # Image is now writeable \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "        bimage = np.zeros((image_height,image_width,3), np.uint8)\n",
    "        cv2.rectangle(bimage,(int(x_min), int(y_min)),(int(x_max), int(y_max)),(0,255,0),2) #(KALAU MAU PAKAI BOUNDING BOX)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "        mp_drawing.draw_landmarks(bimage, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "      \n",
    "        \n",
    " \n",
    "              \n",
    "\n",
    "        image = cv2.rectangle(image,(int(x_min), int(y_min)),(int(x_max), int(y_max)),(255,255,0),2)\n",
    "        \n",
    " \n",
    "        cropped_image = bimage[(int(y_min)):(int(y_max)), (int(x_min)):(int(x_max)),:]\n",
    "        dy =y_max -y_min\n",
    "        dx = x_max -x_min\n",
    "        print(dy,dx)\n",
    "        print(cropped_image.shape) \n",
    "        TimeNow = time.time() \n",
    "        if TimeNow-TimeStart>1/FrameRate:\n",
    "            print(cropped_image.shape)\n",
    "            TimeStart = TimeNow\n",
    "            sFile = DirektoriData+\"\\\\\"+GetFileName()\n",
    "            imsize2=(128,128)\n",
    "            cropped_image = cv2.resize(cropped_image, imsize2)\n",
    "            #cropped_image = cv2.resize(bimage, imsize2)\n",
    "            cv2.imwrite(sFile+'.jpg', cropped_image)\n",
    "            #cv2.imwrite(sFile+'.png', image)\n",
    "        \n",
    "        cv2.imshow('MediaPipe Pose', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "              break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predict Pose based on Video Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictPose(NoKamera,LabelKelas):\n",
    "    ModelCNN = load_model('weight3_test.h5') \n",
    "    \n",
    "\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_drawing_styles = mp.solutions.drawing_styles\n",
    "    mp_holistic = mp.solutions.holistic\n",
    "    imsize=(640, 480)\n",
    "\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(NoKamera,cv2.CAP_DSHOW)\n",
    "    with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "      \n",
    "      while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "          print(\"Ignoring empty camera frame.\")\n",
    "          # If loading a video, use 'break' instead of 'continue'.\n",
    "          continue\n",
    "    \n",
    "\n",
    "        image.flags.writeable = False                  # Image is no longer writeable\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, imsize)\n",
    "        results = holistic.process(image)                 # Make prediction\n",
    "        \n",
    "        height, width, _ = image.shape\n",
    "        coords = []\n",
    "        coordsy = []\n",
    "                                                                                                                                  \n",
    "\n",
    "        if not results.pose_landmarks:\n",
    "                continue\n",
    "        for A in results.pose_landmarks.landmark:\n",
    "\n",
    "            if (A.x>0.01)and(A.x<1-0.01)and(A.y>0.01)and(A.y<1-0.01):\n",
    "                cx, cy = A.x * width, A.y*height \n",
    "                coords.append(cx) \n",
    "                coordsy.append(cy)\n",
    "        if len(coords) ==0:\n",
    "            continue\n",
    "        if len(coordsy) ==0:\n",
    "            continue\n",
    "\n",
    "            #if results.pose_landmarks:\n",
    "            #    pose_landmarks = results.pose_landmarks.landmark\n",
    "            #    for A in pose_landmarks:\n",
    "            #      cx, cy = A.x * image_width, A.y*image_height                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "            #      coords.append(cx) \n",
    "            #      coordsy.append(cy) \n",
    "\n",
    "        x_max = max(coords)\n",
    "        y_max = max(coordsy)\n",
    "        x_min = min(coords)\n",
    "        y_min = min(coordsy)\n",
    "        cv2.rectangle(image, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (255, 255, 0), 2)\n",
    "        \n",
    "        if (int (x_max) < 0):\n",
    "            x_max = 1\n",
    "        elif (int (x_min) < 0):\n",
    "            x_min = 1\n",
    "        elif (int (y_max) < 0):\n",
    "            y_max = 1\n",
    "        elif (int (y_min) < 0):\n",
    "            y_min = 1   \n",
    "        \n",
    "        image.flags.writeable = True                   # Image is now writeable \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "        bimage = np.zeros((height,width,3), np.uint8)\n",
    "        #cv2.rectangle(bimage,(int(x_min), int(y_min)),(int(x_max), int(y_max)),(0,255,0),2)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "        mp_drawing.draw_landmarks(bimage, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) # Draw pose connections\n",
    "       \n",
    "        \n",
    "         \n",
    "              \n",
    "        cropped_image = image[(int(y_min)):(int(y_max)), (int(x_min)):(int(x_max)),:]\n",
    "        idx = Klasifikasi(bimage, ModelCNN)\n",
    "        x=60\n",
    "        y=60\n",
    "        image= cv2.flip(image, 1)\n",
    "    \n",
    "        if idx>=0:\n",
    "            cv2.putText(image,LabelKelas[idx], (x,y), cv2.FONT_HERSHEY_SIMPLEX,2.0, (255, 255, 0), 3)\n",
    "        \n",
    "\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "                \n",
    "       \n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "              break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Classification of Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Klasifikasi(Image,ModelCNN):\n",
    "\n",
    "  X=[]\n",
    "  ls = [];\n",
    "\n",
    "  img= copy.deepcopy(Image)\n",
    "  img=cv2.resize(img,(128,128))\n",
    "  img= np.asarray(img)/255\n",
    "  img=img.astype('float32')\n",
    "  X.append(img)  \n",
    "  X=np.array(X)\n",
    "  X=X.astype('float32')\n",
    "  hs=ModelCNN.predict(X,verbose=0)\n",
    "\n",
    "  if hs.max()>0.5:\n",
    "      idx = np.max(np.where( hs == hs.max()))\n",
    "  else:\n",
    "    idx=-1\n",
    "      \n",
    " \n",
    "  return idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 7. Create a Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelCNN(JumlahKelas):\n",
    "    input_img = Input(shape=(128, 128, 3)) \n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)  \n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)   \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)   \n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)   \n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    #x = Reshape((-1, 32))(x)\n",
    "    #x = LSTM(64, return_sequences=True, activation='relu')(x)\n",
    "    #x = LSTM(128, return_sequences=True, activation='relu')(x)\n",
    "    #x = LSTM(64, return_sequences=False, activation='relu')(x)\n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    #x = Dense(50,activation='relu')(x)\n",
    "    x = Dense(50,activation='sigmoid')(x)\n",
    "    x = Dense(JumlahKelas,activation='softmax')(x)\n",
    "    ModelCNN = Model(input_img, x)  \n",
    "    ModelCNN.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    #ModelCNN.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    #sparse_categorical_crossentropy\n",
    "    #categorical_crossentropy\n",
    "    #plot_model(ModelCNN, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "    return ModelCNN\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 7. Load Citra Training Data (Object Classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadCitraTraining(sDir,LabelKelas):\n",
    "  \n",
    "  JumlahKelas=len(LabelKelas)\n",
    "  TargetKelas = np.eye(JumlahKelas)\n",
    "  \n",
    "  # Menyiapkan variabel list untuk data menampung citra dan data target\n",
    "  X=[]#Menampung Data Citra\n",
    "  T=[]#Menampung Target\n",
    "  for i in range(len(LabelKelas)):    \n",
    "    #Membaca file citra di setiap direktori data set  \n",
    "    DirKelas = os.path.join(sDir, LabelKelas[i])\n",
    "    files = os.listdir(DirKelas)\n",
    "    \n",
    "    for f in files:\n",
    "      ff=f.lower()  \n",
    "      print(f)\n",
    "      #memilih citra dengan extensi jpg,jpeg,dan png\n",
    "      if (ff.endswith('.jpg')):\n",
    "         NmFile = os.path.join(DirKelas,f)\n",
    "         #membaca citra berwarna sebagai data bertipe double \n",
    "         img= np.double(cv2.imread(NmFile,1))\n",
    "         img=cv2.resize(img,(128,128));\n",
    "         #Normalisasi data citra menjadi sehingga maksimum menjadi 1\n",
    "         img= np.asarray(img)/255;\n",
    "         img=img.astype('float32')\n",
    "         #Menambahkan citra dan target ke daftar\n",
    "         X.append(img)\n",
    "         T.append(TargetKelas[i])\n",
    "     #--------akhir loop :Pfor f in files-----------------\n",
    "  #-----akhir  loop :for i in range(len(LabelKelas))----\n",
    "  \n",
    "  #Mengubah List Menjadi numppy array\n",
    "  X=np.array(X)\n",
    "  T=np.array(T)\n",
    "  X=X.astype('float32')\n",
    "  T=T.astype('float32')\n",
    "  return X,T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1. Train the CNN to Recognize => Classify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainCNNLSTM(DirektoriDataSet,LabelKelas,NamaFileBobot ='weight3_test.h5' ):\n",
    "    #tf.config.experimental_run_functions_eagerly(True)\n",
    "    #tf.data.experimental.enable_debug_mode()\n",
    "    #Membaca Data training dan label Kelas \n",
    "    X,D=LoadCitraTraining(DirektoriDataSet,LabelKelas)\n",
    "    JumlahKelas = len(LabelKelas)\n",
    "    #Membuat Model CNN\n",
    "    ModelCNNlstm =ModelCNN(JumlahKelas)\n",
    "    #Trainng\n",
    "    history = ModelCNNlstm.fit(X, D,epochs=20,validation_split=0.1)\n",
    "    #validation_split = 0.5\n",
    "    #Menyimpan hasil learning\n",
    "    ModelCNNlstm.save(NamaFileBobot)\n",
    "    #Mengembalikan output \n",
    "    return ModelCNNlstm,history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2. Make Predictions for the Pose based on Primary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TesPosePrediction(DirDataSet,DirKlasifikasi,LabelKelas,ModelCNN=[]):\n",
    "#Apabila parameter input ModelCNN tidak di isi maka\n",
    "#   akan menggunakan bobot pada file 'weight.h5\n",
    "  if not(ModelCNN):\n",
    "      ModelCNN = load_model('weight3_test.h5') \n",
    "      \n",
    "#Menyiapkan Data input Yang akan di kasifikasikan\n",
    "  X=[]\n",
    "  ls = [];\n",
    "  DirKelas = DirDataSet+\"\\\\\"+DirKlasifikasi\n",
    "  print(DirKelas)\n",
    "  files = os.listdir(DirKelas)\n",
    "  n=0;\n",
    "  for f in files:\n",
    "      ff=f.lower()  \n",
    "      print(f)\n",
    "      if (ff.endswith('.jpg')):\n",
    "         ls.append(ff) \n",
    "         NmFile = os.path.join(DirKelas,f)\n",
    "         img= cv2.imread(NmFile,1)\n",
    "         img=cv2.resize(img,(128,128))\n",
    "         img= np.asarray(img)/255\n",
    "         img=img.astype('float32')\n",
    "         X.append(img)\n",
    "     #----Akhir if-------------\n",
    "  #---Akhir For \n",
    "  X=np.array(X)\n",
    "  X=X.astype('float32')\n",
    "  #Melakukan prediksi Klasifikasi\n",
    "  hs=ModelCNN.predict(X)\n",
    "  \n",
    "  LKlasifikasi=[];\n",
    "  LKelasCitra =[];\n",
    "  n = X.shape[0]\n",
    "  for i in range(n):\n",
    "      v=hs[i,:]\n",
    "      if v.max()>0.5:\n",
    "          idx = np.max(np.where( v == v.max()))\n",
    "          LKelasCitra.append(LabelKelas[idx])\n",
    "      else:\n",
    "          idx=-1\n",
    "          LKelasCitra.append(\"-\")\n",
    "      #------akhir if\n",
    "      LKlasifikasi.append(idx);\n",
    "  #----akhir for\n",
    "  LKlasifikasi = np.array(LKlasifikasi)\n",
    "  return ls, hs, LKelasCitra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3. Collect Dataset and Store to Assigned Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil data set dan menyimpan ke folder\n",
    "Dataset(0,\"Paman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data Set\n",
    "DirektoriDataSet=\"D:\\\\temp\\\\trainingdataset4\"\n",
    "#   Data Set disimpan dalam direktori yang sama dengan nama kelas    \n",
    "\n",
    "#b. Label Data Set \n",
    "LabelKelas=(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\")\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "#c. Inisialisasi parameter Training\n",
    "#JumlahEpoh = 100;\n",
    "\n",
    "#d. training\n",
    "ModelCNN,history = TrainCNNLSTM(DirektoriDataSet,LabelKelas )\n",
    "ModelCNN.summary()\n",
    "\n",
    "#c. Menampilkan Grafik Loss dan accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss/accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.legend(['train','test'])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.4. Predict Pose Test based on Classified Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelKelas=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\"]\n",
    "\n",
    "PredictPose(0,LabelKelas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelKelas=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\"]\n",
    "DirektoriDataSet=\"D:\\\\temp\\\\trainingdataset4\"\n",
    "\n",
    "DirKlasifikasi=\"C\"\n",
    "Res = TesPosePrediction(DirektoriDataSet,DirKlasifikasi,LabelKelas)\n",
    "print(Res[0])\n",
    "print(Res[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Create a Confusion Matrix to Assess Overall Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the predicted labels and true labels for test data\n",
    "X_test, D_test = LoadCitraTraining(DirektoriDataSet, LabelKelas)\n",
    "\n",
    "# Predict labels for the test data\n",
    "predicted_labels = ModelCNN.predict(X_test)\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Convert one-hot encoded true labels to class labels\n",
    "true_labels = np.argmax(D_test, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(LabelKelas))\n",
    "plt.xticks(tick_marks, LabelKelas, rotation=45)\n",
    "plt.yticks(tick_marks, LabelKelas)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Determine Result Accuracy & Precision, Correction, Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the predicted labels and true labels for test data\n",
    "X_test, D_test = LoadCitraTraining(DirektoriDataSet, LabelKelas)\n",
    "\n",
    "# Load or initialize your trained model\n",
    "model = load_model('weight3_test.h5')  # Replace 'path_to_your_model.h5' with the actual path to your model\n",
    "\n",
    "# Predict labels for the test data\n",
    "predicted_labels = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Convert one-hot encoded true labels to class labels\n",
    "true_labels = np.argmax(D_test, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate precision for each class\n",
    "precisions = precision_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "# Calculate recall for each class\n",
    "recalls = recall_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "# Calculate F1-score for each class\n",
    "f1_scores = f1_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "# Print the precision, recall, and F1-score table\n",
    "print(\"Class\\t\\tPrecision\\t1-Precision\\tRecall\\t\\t1-Recall\\tF1-score\")\n",
    "for i in range(len(LabelKelas)):\n",
    "    print(\"{}\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\\t\\t{:.4f}\".format(LabelKelas[i], precisions[i], 1-precisions[i],\n",
    "                                                                         recalls[i], 1-recalls[i], f1_scores[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
